{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Logistic Regreesion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Logistic Regression Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[기존 접근(회귀 등)의 문제점들]\n",
    "- 1이상 또는 0이하의 수들이 나오는걸 어떻게 해석?\n",
    "- 1또는 0으로 정확히 표현 가능한가?\n",
    "- 변수가 Y에 영향을 주는 정도가 비례하는가?\n",
    "- **확률로 발생할 사건의 가능성을 표현해야함**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution : 확률로 나타내자 !**\n",
    "- sigmoid 등으로 확률로 표현하여 예를들어 0.5보다 크면 True, 작으면 False 등으로 판별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Sigmoid Function]**\n",
    "- 분류의 가능성을 확률로 얘기하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Odds Ratio]** : 특정 사건이 일어날 확률과 일어나지 않을 확률의 비율\n",
    "> $\\frac{P(X)}{1-P(X)} = \\frac{일어날확률}{일어나지않을확률}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Logit function]** : X값이 주어졌을 때, y의 확률을 이용한 log odds\n",
    "> $logit(p(y=1|x)) = log_{e} (\\frac{p}{1-p})$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $= log_{e} (p) - log_{e} (1-p)$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$= -log_{e} (\\frac{1}{p} - 1) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Sigmoid(=Logsitic) Function]** : Logit함수의 역함수로 z에 관한 확률을 산출\n",
    "> $f(z) = y = -log_{e} (\\frac{1}{z} -1)$ 이걸 역함수로 바꾸면<br>\n",
    "> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$z = -log_{e} (\\frac{1}{y} - 1)$ y에 관한 정리\n",
    "- **우리가 원하는 확률값을 결과값으로 뱉음 !**<br>\n",
    "> $z = -log_{e} (\\frac{1}{y} - 1)$ <br>\n",
    "> $e^{(-z)} = \\frac{1-y}{y}$ <br>\n",
    "> $y * e^{(-z)} + y = 1$ <br>\n",
    "> $y(e^{(-z)} + 1) = 1$ <br>\n",
    "> **$y = \\frac{1}{1+e^{(-z)}}$**\n",
    "- Logistic Function = Inverse of logit function\n",
    "- **미분가능한 연속구간**으로 변환, S자 형태를 닮아서 sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://ifh.cc/g/5YMwcJ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $log_{e} (\\frac{1-p}{p}) = z = w_0 x_0 + w_1 x_1 + \\cdots +w_n x_n$\n",
    "- z값을 찾아서 어떤 사건이 일어날 확률값을 구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Logistic Regression에서 Weight 학습하기]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[가설함수]**\n",
    "> $h_\\theta (x) = g(z) = \\frac{1}{1 + e^{-z}}$&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ($0 \\le h_\\theta (x) \\le 1$)<br>\n",
    "> where : <br>\n",
    "> &nbsp;&nbsp;$z = w_0 x_0 + w_1 x_1 + \\cdots +w_n x_n$<br>\n",
    "> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$ = \\theta^T x$\n",
    "\n",
    "- <span style = 'background-color: #fff5b1'> h함수는 확률값을 뱉어낸다 !</span>\n",
    "\n",
    "![img](https://ifh.cc/g/5YMwcJ.png)\n",
    "- thereshold를 어떤값으로 하느냐에 따라 그값보다 크면 사건발생, 작으면 사건발생X로 보통 판별한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Training theta]**\n",
    "> $h_\\theta (x) = \\frac{1}{1 + e^{-\\theta T X}}$ <br>\n",
    "> $\\theta^T X = w_0 x_0 + w_1 x_1 + \\cdots +w_n x_n$<br>\n",
    "> y = 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Cost Function]**\n",
    "- y가 1일 때, y가 0일 때로 나눠서 cost function 계산\n",
    "- y가 1일 때는, 가설함수의 값이 커질수록(사건이 발생했다고 예측할수록) cost값이 작아진다.\n",
    "- y가 0일 때는, 가설함수의 값이 작아질수록(사건이 발생하지않았다고 예측할수록) cost값이 작아진다.\n",
    "> $ Cost(h_\\theta(x), y)=\n",
    "> \\begin{cases}\n",
    "> -log(h_\\theta(x)),\\; if \\; y = 1 \\\\\n",
    "> -log(1 - h_\\theta(x)),\\; if \\; y = 0\n",
    "> \\end{cases}$\n",
    "\n",
    "![img](https://ifh.cc/g/pdLDWT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 함수식에서 $y=0$일 때, $y=1$일 때 둘 다를 하나의 식으로 합치면\n",
    "> $\\begin{matrix}\n",
    ">J(\\theta) &=& \\frac{1}{m} \\sum_{i=1}^m Cost(h_\\theta (x^{(i)}), y^{(i)}) \\\\\n",
    ">       &=& -\\frac{1}{m} \\sum_{i=1}^m [y^{(i)}logh_\\theta (x^{(i)}) + (1 - y^{(i)})log(1-h_\\theta (x^{(i)}))]\n",
    ">\\end{matrix}$\n",
    "\n",
    "**Cost function($J(\\theta)$)를 최소화하는 $\\theta$를 찾는게 우리의 목표 !**<br>\n",
    "우선 $J(\\theta)$를 정리하면"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $\\begin{matrix}\n",
    "> J(\\theta) &=& -\\frac{1}{m} \\sum_{i=1}^m [-y^{(i)}(log(1 + e^{-\\theta x^i})) + (1 - y^i)(-\\theta x^i - log(1 + e^{-\\theta x^i}))] \\\\\n",
    ">           &=& -\\frac{1}{m} \\sum_{i=1}^m [y_i \\theta x^i - \\theta x^i - log(1 + e^{-\\theta x^i})] \\\\\n",
    "            &=& -\\frac{1}{m} \\sum_{i=1}^m [y_i \\theta x^i - log(1 + e^{\\theta x^i})]\n",
    "> \\end{matrix}$\n",
    "\n",
    "위식을 $\\theta$에 관하여 미분하면\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $\\frac{\\partial}{\\partial \\theta_j} y_i \\theta x^i = y_i x^i_j$ <br>\n",
    "> $\\frac{\\partial}{\\partial \\theta_j} log(1 + e^{\\theta x^i}) = \\frac{x^i_j e^{\\theta x^i}}{1 + e^\\theta x^i} = x^i_j h_\\theta(x^i)$\n",
    "\n",
    "> **<span style = 'background-color: #fff5b1'>따라서!!</span>** **$\\frac{\\partial}{\\partial \\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h_\\theta(x^i) - y^i)x^i_j$** <br><br><br>\n",
    "> $\\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j}J(\\theta)$ <br>\n",
    "> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$:=\\theta_j - \\alpha \\sum_{i=1}^m (h_\\theta(x^i) - y^i)x^i_j$\n",
    "- **모든 $\\theta_j$ 동시에 업데이트**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numpy implementation**\n",
    "- Logistic Regression을 Numpy로 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data : 데이터 과학자로써의 경력과 소득, 유료계정 전환여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ (0.7, 48000, 1)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('hyeooi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c36318f1f175f6468c37ab31a9400557c0f81fa065037d590afb13b0d6bda87f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
