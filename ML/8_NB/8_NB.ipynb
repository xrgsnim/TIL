{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Naive Bayes Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Probability Overview]** - 머신러닝의 학습방법들\n",
    "- Gradient descent based learning\n",
    "- Probability theory based learning - 이번에 배울거\n",
    "- Information theory based learning\n",
    "- Distance similarity based learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probability**\n",
    "- 이산형 값\n",
    "> ##### $P(X) = \\frac{count(Event_X)}{count(ALL_{Event})}$\n",
    "\n",
    "- 연속형 값\n",
    "> $P(-\\infty < x < \\infty) = \\int_{-\\infty}^{\\infty} f(x)dx = 1$\n",
    "<br><br><br>\n",
    "\n",
    "**Basic concepts of probability**\n",
    "> $0 \\le P(E) \\le 1$ <br>\n",
    "> $P(S) = \\sum_{i=1}^N P(E_i) = 1$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if all $E_i$ are independent\n",
    "<br><br><br>\n",
    "\n",
    "**Conditional probability**\n",
    "> $P(A|B) = \\frac{P(A \\cap B)}{P(B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "**[Bayes's Theorem]**\n",
    "- 경험에 의한 확률 업데이트\n",
    "- 주어진 사전 확률에서 특정 사건 발생을 통해 사후 확률로 계속해서 업데이트(ex.개표방송)\n",
    "- 빈도주의 vs 베이즈주의\n",
    "- 객관적 확률은 존재하지 않는다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probability updated**\n",
    "- 특정 사건이 일어남에 따라 확률을 업데이트(ex. 퀸찾기 카드게임)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayes's theorem**\n",
    "> $P(A|B) = \\frac{P(A \\cap B)}{P(B)}$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$P(B|A) = \\frac{P(A \\cap B)}{P(A)}$ <br>\n",
    "> $P(A \\cap B) = P(B)P(A|B) = P(A)|P(B|A)$ <br><br>\n",
    "> $P(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(A)P(B|A)}{P(B)}$\n",
    "- 다시말해서, 사건B가 일어났을 때의 사건A가 일어날 확률은, 사건B가 일어났을때, 사건A가 일어날 확률은 주어져있고, 사건A가 일어났을때 사건B가 일어날 확률을 거기에 곱해주면 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $P(H|D) = \\frac{P(H)P(D|H)}{P(D)}$ <br>\n",
    "(H is Class &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; D is Data)\n",
    "- P(H|D) : 사후확률, 어떤 데이터가 주어졌을 때의 가설이 발생할(발생하지않을) 확률 (H : 가설함수)\n",
    "- P(D) : 전체확률, 데이터가 발생할 확률(Evidence)\n",
    "- P(H) : 사전확률, 예) 1000개중 $y_1$= 700, $y_2$=300개면 P($H_1$)=700/1000\n",
    "- 결국은 주어진 데이터(D) X를 통해 클래스(D) Y를 찾는 작업\n",
    "- 나중에는 P(D)는 고정값이 되고, P(H)는 주어져서 결국 P(D|H), 우도를 찾는게 가장 중요해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "**[Naive Bayes Classifier]**<br><br>\n",
    "예제로 풀어보기 - Viagra 스팸 필터기\n",
    "- Viagra라는 단어의 유무를 통해 스팸 여부 확인\n",
    "- Viagra 단어가 들어가면 무조건 스팸?\n",
    "- 어느정도 확률로 스팸이라고 해야할까? <br><br>\n",
    "![img](https://ifh.cc/g/3vSPxP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $P(spam | viagra) = \\frac{P(spam)P(viagra|spam)}{P(viagra)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viagra</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   viagra  spam\n",
       "0       1     1\n",
       "1       0     0\n",
       "2       0     0\n",
       "3       0     0\n",
       "4       0     0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viagra_spam = {'viagra': [1,0,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,1],\n",
    "               'spam': [\n",
    "                   1,0,0,0,0,0,1,0,1,0, 0,0,0,0,0,0,0,1,1,1\n",
    "               ]}\n",
    "\n",
    "df = pd.DataFrame(viagra_spam, columns=['viagra', 'spam'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data = df.values\n",
    "np_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(viagra), P(spam), P(V $\\cap$ S), P($N^c \\cap S$) 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_viagra = sum(np_data[:, 0] == 1) / len(np_data)\n",
    "p_spam = sum(np_data[:, 1] == 1) / len(np_data)\n",
    "p_v_cap_s = sum((np_data[:, 0] == 1) & (np_data[:, 1] == 1)) / len(np_data)\n",
    "p_n_v_cap_s = sum((np_data[:, 0] == 0) & (np_data[:, 1]== 1)) / len(np_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(Spam | Viagra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_spam * (p_v_cap_s / p_spam) / p_viagra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(Spam | ~Viagra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2142857142857143"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_spam * (p_n_v_cap_s / p_spam) / (1-p_viagra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "**제대로된 스팸 필터기를 만들어보자**\n",
    "- Viagra 단어외에 영향을 주는 단어들은?\n",
    "- 오히려 스팸을 제외해주는 단어는 어떻게 찾을까?\n",
    "- 한번에 여러 단어들을 고려하는 필터기를 만들어보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature의 확장**<br><br>\n",
    "$P(spam | viagra)$ &nbsp;&nbsp;( spam : y &nbsp;&nbsp;&nbsp;&nbsp; viagra : x )<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\Downarrow$<br>\n",
    "$P(spam | viagra, hello, lucky, marketing, \\cdots)$\n",
    "- y는 그대로 1또는 0을 가지지만, x는 $x_1, x_2, x_3 \\cdots $로 확장됨\n",
    "- 변수가 많을 때, 조건부 확률의 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Multivariate multiplication rule ]**\n",
    "> $P(Y | X_1 \\cap X_2) = \\frac{P(Y \\cap X_1 \\cap X_2)}{P(X_1 \\cap X_2)}$<br>\n",
    "> $P(Y \\cap X_1 \\cap X_2) = P(Y | X_1, X_2) P(X_1 \\cap X_2)$ <br><br>\n",
    "> $P(X_1, X_2, X_3, \\cdots, X_n)$<br>\n",
    "> $= P(X_1)P(X_2|X_1)P(X_3|X_1, X_2) \\cdots P(X_n|X_1 \\cdots X_{x-1})$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problems!**\n",
    "- 변수가 늘어날수록 급격히 계산이 어려워짐\n",
    "- Feature의 차원이 증가하면 Sparse Vector가 생성 $\\rightarrow$ 확률이 0이 되는 값이 늘어남"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[ Naive Bayes Classifier ]**\n",
    "- 접근방향 : 복잡하게 하지만고 단순(naive)하게 해결하자\n",
    "- 각 변수의 관계가 독립임을 가정\n",
    "- 계산이 용이해지고, 성능이 생각보다 좋음..!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Joint Probability**\n",
    "> $P(A \\cap B) = P(A)P(B)$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if A and B are independent<br><br>\n",
    "> $P(Y|X_1 \\cap X_2) = \\frac{P(Y)P(X_1 \\cap X_2 | Y)}{P(X_1 \\cap X_2)}$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$= \\frac{P(Y)P(X_1|Y)P(X_2|Y)}{P(X_1)P(X_2)}$\n",
    "- 이전의 Multivariate multiplication rule보다는 더 간결해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes Classifier**\n",
    "> ##### $P(Y|X_1 \\cap X_2) = \\frac{P(Y) P(X_1 \\cap X_2 | Y)}{P(X_1 \\cap X_2)} = \\frac{P(Y)P(X_1|Y)P(X_2|Y)}{P(X_1)P(X_2)}$<br><br>\n",
    "> ##### <span style='background-color:#fff5b1'>$P(Y_c | X_1, \\cdots,X_n) > = \\frac{P(Y_c) \\prod_{i=1}^n P(X_i |Y_c)}{\\prod_{i=1}^n P(X_i)}$</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;$Y_c$ : label ($Y_c$ = 0 or 1)\n",
    "- $X_1$부터 $X_n$까지의 Data가 주어졌을 때, P(Y=1)과 P(Y=0)중에 더 큰 값을 채택하여 모든 데이터마다 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Issue!**\n",
    "- 너무 많은 확률값$(0 \\le P \\le 1) \\rightarrow$ 0에 수렴하게 되는문제\n",
    "- 곱하지 말고 더하자 $\\rightarrow$ log\n",
    "<br><br>\n",
    "> $log({P(Y_c)\\prod_{i=1}^n P(X_i|Y_c)}) = log P(Y_c) + \\sum_{i=1}^n log P(X_i |Y_c)$\n",
    "> ##### <span style='background-color:#fff5b1'>$P(Y_c | X_1, \\cdots, X_n) = \\frac{P(Y_c) \\prod_{i=1}^n P(X_i|Y_c)}{\\prod_{i=1}^n P(X_i)}$</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $Y_c$ : label ($Y_c$ = 0 or 1)\n",
    "- 분모에서 $X_i$는 피쳐이기 때문에 prod의 결과값은 고정되어있어서 중요하지 않다.<br>\n",
    "$\\divideontimes$ Likelihood : 가능도 <br>\n",
    "<br><br>\n",
    "- 확률이 0인 변수들이 존재함 $\\rightarrow$ 전체값 0\n",
    "- 작게나마 확률이 나올 수 있도록변경 $\\rightarrow$ **스무딩**\n",
    "> #### $P(X|Y) = \\frac{count(X \\cap Y) + k}{count(Y) + (k\\;*\\;|number\\;of\\;class|)}$\n",
    "- 분모분자에 k라는 상수값을 임의로 넣어서 값을 좀 더 평탄하게(generalize) 해준다. 다만 count값들에 비해 k가 커버리면 차이가 더 흐려질수도 있으니 주의\n",
    "- 스무딩 기법을 사용하면 확률이 0으로 산출되지도 않고 generalize의 효과도 볼수있다.\n",
    "- binary한 분류문제에서는 Y=1 or 0이 될테니까 number of class=2가 된다\n",
    "> ##### <span style='background-color:#fff5b1'> $log{P(Y_c)\\prod_{i=1}^n P(X_i|Y_c)} = log P(Y_c) + \\sum_{i=1}^n logP(X_i | Y_c)$</span>\n",
    "- 최종식. 우변에서 sum항에 스무딩을 먹여줘서 0인 값이 없도록 한다.\n",
    "<br><br>\n",
    "- NB의 핵심 : 최종 식 도출 + 스무딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### **NB Classifier Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset - German Credit**\n",
    "- 대출 사기인가 아닌가를 예측하는 문제\n",
    "- 데이터를 NB에 맞도록 간단하게 변환\n",
    "- Binary 데이터들로 이루어진 대출 사기 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Load, Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>History</th>\n",
       "      <th>CoApplicant</th>\n",
       "      <th>Accommodation</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>paid</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>paid</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>paid</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>rent</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>arrears</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  History CoApplicant Accommodation  Fraud\n",
       "0   1  current        none           own   True\n",
       "1   2     paid        none           own  False\n",
       "2   3     paid        none           own  False\n",
       "3   4     paid   guarantor          rent   True\n",
       "4   5  arrears        none           own  False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/TeamLab/machine_learning_from_scratch_with_python/master/code/ch11/fraud.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False,  True, False,  True, False, False, False,\n",
       "        True, False,  True,  True, False, False, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df[\"ID\"]\n",
    "\n",
    "Y_data = df.pop(\"Fraud\")\n",
    "Y_data = Y_data.as_matrix()\n",
    "Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>History</th>\n",
       "      <th>CoApplicant</th>\n",
       "      <th>Accommodation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>current</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paid</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paid</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>rent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arrears</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   History CoApplicant Accommodation\n",
       "0  current        none           own\n",
       "1     paid        none           own\n",
       "2     paid        none           own\n",
       "3     paid   guarantor          rent\n",
       "4  arrears        none           own"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**\n",
    "- History_arrears = x1, History_current = x2 ... 이런식으로 onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>History_arrears</th>\n",
       "      <th>History_current</th>\n",
       "      <th>History_none</th>\n",
       "      <th>History_paid</th>\n",
       "      <th>CoApplicant_coapplicant</th>\n",
       "      <th>CoApplicant_guarantor</th>\n",
       "      <th>CoApplicant_none</th>\n",
       "      <th>Accommodation_free</th>\n",
       "      <th>Accommodation_own</th>\n",
       "      <th>Accommodation_rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   History_arrears  History_current  History_none  History_paid  \\\n",
       "0                0                1             0             0   \n",
       "1                0                0             0             1   \n",
       "2                0                0             0             1   \n",
       "3                0                0             0             1   \n",
       "4                1                0             0             0   \n",
       "\n",
       "   CoApplicant_coapplicant  CoApplicant_guarantor  CoApplicant_none  \\\n",
       "0                        0                      0                 1   \n",
       "1                        0                      0                 1   \n",
       "2                        0                      0                 1   \n",
       "3                        0                      1                 0   \n",
       "4                        0                      0                 1   \n",
       "\n",
       "   Accommodation_free  Accommodation_own  Accommodation_rent  \n",
       "0                   0                  1                   0  \n",
       "1                   0                  1                   0  \n",
       "2                   0                  1                   0  \n",
       "3                   0                  0                   1  \n",
       "4                   0                  1                   0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df = pd.get_dummies(df)\n",
    "x_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- onehot encoding의 결과로 x1부터 x10까지의 feature들이 나왔음\n",
    "- 따라서 x의 벡터들이 주어졌을 때, P(y=1)과 P(y=0)중 더 큰걸 선택할수 있도록 classifier를 만들어줄거임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = x_df.as_matrix()\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modeling**\n",
    "##### $P(Y_c | X_1, \\cdots, X_n) = \\frac{P(Y_c) \\prod_{i=1}^n P(X_i|Y_c)}{\\prod_{i=1}^n P(X_i)}$<br>\n",
    "- 위 식을 따르는 Naive Bayes's Classifier를 만든다.\n",
    "- $x_1, \\cdots ,x_n$ 은 $x_1, \\cdots ,x_{10}$ 까지\n",
    "- 분모는 모든 y의 값에 적용되니 무시해도된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3, 0.7)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Y_True = sum(Y_data == True) / len(Y_data)\n",
    "P_Y_False = 1 - P_Y_True\n",
    "\n",
    "P_Y_True, P_Y_False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Y의 Index : 사기가 있는것과 없던것의 인덱스 구분\n",
    "- np.where() : 괄호안의 조건에 성립하는것의 인덱스값을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 0,  3,  5,  9, 11, 12], dtype=int64),),\n",
       " (array([ 1,  2,  4,  6,  7,  8, 10, 13, 14, 15, 16, 17, 18, 19],\n",
       "        dtype=int64),))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사기 당한 인덱스들\n",
    "ix_Y_True = np.where(Y_data)\n",
    "# 사기 안당한 인덱스들\n",
    "ix_Y_False = np.where(Y_data == False)\n",
    "\n",
    "ix_Y_True, ix_Y_False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $P(X_i | Y_c) = \\frac{Count(X_i \\cap Y = 1)}{Count(Y=1)} \\cdots$ (Y=0일때도)\n",
    "- (x_data[ix_Y_True].sum(axis=0)) 부분 설명<br><br>\n",
    "![img](https://ifh.cc/g/52Dvnx.png)\n",
    "- 위에서 뽑은 인덱스들의 행만 뽑은 뒤 각 피쳐별로 위에서 아래로(axis=0) 쭉 sum 진행.\n",
    "- 그 결과값에 인덱스의 갯수로 나눠줘서 위의 식 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.16666667, 0.5       , 0.16666667, 0.16666667, 0.        ,\n",
       "        0.16666667, 0.83333333, 0.        , 0.66666667, 0.33333333]),\n",
       " array([0.42857143, 0.28571429, 0.        , 0.28571429, 0.14285714,\n",
       "        0.        , 0.85714286, 0.07142857, 0.78571429, 0.14285714]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_x_y_true = (x_data[ix_Y_True].sum(axis=0)) / sum(Y_data == True) # 분모 : count(Y=1)을 의미\n",
    "p_x_y_false = (x_data[ix_Y_False].sum(axis=0)) / sum(Y_data == False) # 분모 : count(Y=0)을 의미\n",
    "\n",
    "p_x_y_true, p_x_y_false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifier**\n",
    "- 사실 아래 식에서 우변의 각 항에 log를 취해주거나 그게 아니면 저 두 항을 서로 곱해줘야하는데 값의 큰 차이가 없어서 더해주면서 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6333333333333333, 1.7714285714285714)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = [0, 1, 0, 0, 0, 1, 0, 0, 1, 0]\n",
    "\n",
    "p_y_true_test = P_Y_True + p_x_y_true.dot(x_test) # P(Y = 1)\n",
    "p_y_false_test = P_Y_False + p_x_y_false.dot(x_test) # P(Y = 0)\n",
    "\n",
    "p_y_true_test, p_y_false_test\n",
    "# P(Y = 1) < P(Y = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_y_true_test < p_y_false_test\n",
    "# 따라서 x_test 데이터에 대해서는 대출사기가 아니라고 하는것이 맞다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Multinomial Naive Bayes**\n",
    "- X값이 Binary가 아니라 1이상의 값을 가지는 문제\n",
    "- 일반적으로 Text 문제를 분류할 때 많이 쓰임\n",
    "- 단어의 존재 유무가 아닌 단어의 **출현횟수** Feature로\n",
    "- 구성된 벡터가 sparse할 때 많이 쓰임 ([0 0 0 1 0 0 7 0 0 1 0 0]같은)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Text를 문자로 표현하는 방법 ]**<br><br>\n",
    "**문자를 Vector로 - One hot Encoding**\n",
    "- 하나의 단어를 Vector의 Index로 인식, 단어 존재시 1 없으면 0<br><br>\n",
    "![img](https://ifh.cc/g/bSmZjf.png)\n",
    "- 어떤 단어 자체를 인덱스를 먹여서 존재여부로 표현\n",
    "<br><br>\n",
    "- 하지만 한 문장에서 한번에 여러 단어가 나올때는..?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Bag of words ]**\n",
    "- 단어별(One-hot)로 인덱스를 부여해서 한 문장(또는 문서)의 단어의 개수를 Vector로 표현\n",
    "- 순서의 정보는 표현할 수 없지만 성능이 강력해서 주로 이용됨<br><br>\n",
    "![img](https://ifh.cc/g/9Dwk92.png)<br>\n",
    "(문장에서 the가 두번나오니 the의 초록색 박스의 숫자는 2가 되어야함 )<br>\n",
    "\n",
    "- Bag of words 예시<br>\n",
    "![img](https://ifh.cc/g/gqFPVY.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Multinomial Naive Bayes ]**\n",
    "- 식 계산하는 방식이 다름<br>\n",
    "\n",
    "> $\\prod_{i=1}^n P(X_i | Y_c)$에서의 $P(X_i | Y_c)$<br>\n",
    "> ### $ \\Rightarrow P(X_i | Y_c) = \\frac{\\sum t f(x_i, d \\in Y_c) + \\alpha}{\\sum N_{d \\in Y_c} + \\alpha \\centerdot V}$\n",
    "\n",
    "- $\\sum t f(x_i, d \\in Y_c)$ : 특정 클래스에서 특정 x의 갯수들의 합\n",
    "- $\\sum N_{d \\in y_c}$ : 클래스에 속한 모든 단어의 갯수의 합\n",
    "- $x_i$ : $Y_c$가 특정상황일때, feature의 출현횟수\n",
    "- V : feature의 갯수(단어의 갯수)\n",
    "- $\\alpha$ : 스무딩 파라메터<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 풀어보기<br><br>\n",
    "![img](https://ifh.cc/g/zJMXB9.png)<br><br>\n",
    "> ##### $P(X_i | Y_c) = \\frac{\\sum tf(x_i, d \\in Y_c) + \\alpha}{\\sum N_{d \\in Y_c} + \\alpha \\centerdot V} \\cdots\\cdots \\mathit{1}$\n",
    "> ##### $P(Y_c | X_1, \\cdots, X_n) = \\frac{P(Y_c) \\prod_{i=1}^n P(X_i|Y_c)}{\\prod_{i=1}^n P(X_i)} \\cdots\\cdots \\mathit{2}$<br>\n",
    "**[ Train ]**<br>\n",
    "- P(c) = 3/4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;P(j) = 1/4<br>\n",
    "$\\alpha=2$로 가정\n",
    "\n",
    "- $X_1$ = Chinese<br>$X_2$ = Beijing<br>$X_3$ = Shanghai<br>$X_4$ = Macao<br>$X_5$ = Tokyo<br>$X_6$ = Japan\n",
    "\n",
    "식 1의 $P(X_i|Y_c)$구하기 위해서 $P(X_i | c)$과$P(X_i | j)$를 구할것임<br><br>\n",
    "**1**. $P(X_1 | c)$ : class가 china일 때, $X_1$이 들어있는 확률 \n",
    "- V = 6\n",
    "- $N_{d \\in c}$ = 8\n",
    "- $\\sum tf(x_1, d \\in c)$ = china클래스 안에서 Chinese의 갯수 = 5\n",
    "- 따라서, $P(X_1 | c) = \\frac{5 + 2}{8 + 12}$\n",
    "\n",
    "**2**. $P(X_i | j)$ : class가 japan일 때, $X_1$이 들어있는 확률\n",
    "- V = 6\n",
    "- $N_{d \\in j}$ = 3\n",
    "- $\\sum tf(x_1, d \\in c)$ = japan클래스 안에서 Chinese의 갯수 = 1\n",
    "- 따라서, $P(X_1 | j) = \\frac{1 + 2}{3 + 12}$\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\vdots$<br>\n",
    "- $X_6$까지 모두 구한다음 $\\prod_{i=1}^n P(X_i| c)$와 $\\prod_{i=1}^n P(X_i| j)$를 해서 다 곱해준 뒤 식 2를 구할 때 활용한다.<br><br><br>\n",
    "\n",
    "**[ Test ]**\n",
    "- 식 2를 활용하여 주어진 데이터가 class c에 속할지 j에 속할지 구분해야된다.\n",
    "- Test데이터에 Chinese, Tokyo, Japan이라는 단어가 있으니 $X_1,\\ X_5,\\ X_6$이 있다고 본다.\n",
    "- 따라서 최종적으로 식2를 활용하여,\n",
    "> #### $P(c|X_1, \\cdots, X_n) = \\frac{P(c) * P(X_1|c)* P(X_5|c)* P(X_6|c)}{\\prod_{i=1}^n P(X_i)}$\n",
    "> #### $P(j|X_1, \\cdots, X_n) = \\frac{P(j) * P(X_1|j)* P(X_5|j)* P(X_6|j)}{\\prod_{i=1}^n P(X_i)}$\n",
    "- 위 두 식의 결과 중 더 큰값이 나오는 쪽으로 분류하면 된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "#### **[ Gaussian NB ]**\n",
    "- Category데이터가 아닌 Continuous한 경우에 적용되는 NB\n",
    "- Continuous 데이터의 적용을 위해 y의 분포를 **정규분포(gaussian)으로 가정**함\n",
    "- 확률밀도 함수 상의 해당 값 x가 나올 확률로 NB를 구현함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### $P(x_i | Y_c) = \\frac{1}{\\sqrt{2\\pi \\sigma^2_{Y_c}}}exp(- \\frac{(x_i - \\mu Y_c)^2}{2\\sigma^2_{Y_c}})$\n",
    "- 특정 $Y_c$에 대한 $X_i$의 평균 표준편차를 $\\mu$, $\\sigma$에 대입\n",
    "- 예) Y=1일때, $X_1$이라는 피쳐의 $\\mu$값과 $\\sigma$값을 위 식에 대응시켜줌\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "**예제 풀어보기**\n",
    "<br><br>\n",
    "![img](https://ifh.cc/g/xHX3v9.png)\n",
    "![img](https://ifh.cc/g/tsQKla.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
